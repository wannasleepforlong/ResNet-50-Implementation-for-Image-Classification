# ResNet-50-Implementation-for-Image-Classification
Implementing ResnNet-50 for image classification purposes by transfer learning

ResNet architecture is very good to fight vanishing gradient. In the cases where you train very deep neural networks, gradients tend to become null, the resnet approach can help fight this.

There is ResNet-18, ResNet-34, ResNet-50, ResNet-101 and ResNet-152 as well where the numbers represent the number of layers in the architecture.

The ResNet model architecture allows the training error to be reduced with a deeper network through connection skip.Residual neural networks ignore some connections and make double or triple layer jumps that contain non-linearities (ReLU).

We have used Transfer learning in the following project,

Transfer learning, used in machine learning, is the reuse of a pre-trained model on a new problem. In transfer learning, a machine exploits the knowledge gained from a previous task to improve generalization about another.

If a model is trained on a database, there is no need to re-train the model from scratch to fit a new set of similar data.
This saves lot of time by achieving better performance in fewer epochs.

Thanks senpais, for saving our time †(≧◡≦)

I would aslo like to thank (Nachiketa Hebbar)[https://www.youtube.com/watch?v=JcU72smpLJk&ab_channel=NachiketaHebbar] for teaching me. Do check his channel out.

